{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "4dc58cdb",
   "metadata": {},
   "source": [
    "## Import Dependencies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "1ee03ae8",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#!pip install stable-baselines3[extra]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "6d540a89",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import gym \n",
    "from stable_baselines3 import PPO\n",
    "from stable_baselines3.common.vec_env import DummyVecEnv\n",
    "from stable_baselines3.common.evaluation import evaluate_policy"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "afd6d854",
   "metadata": {},
   "source": [
    "## load enviroment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "c284c5ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "enviroment_name = 'CartPole-v0'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "f5eeda21",
   "metadata": {},
   "outputs": [],
   "source": [
    "env = gym.make(enviroment_name, render_mode='human')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "fc8f4f57",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode:1 Score:23.0\n",
      "Episode:2 Score:10.0\n",
      "Episode:3 Score:13.0\n",
      "Episode:4 Score:13.0\n",
      "Episode:5 Score:43.0\n"
     ]
    }
   ],
   "source": [
    "episodes = 5\n",
    "for episode in range(1, episodes+1):\n",
    "    state = env.reset()\n",
    "    done = False\n",
    "    score = 0 \n",
    "    \n",
    "    while not done:\n",
    "        env.render()\n",
    "        action = env.action_space.sample()\n",
    "        n_state, reward, done, info, g = env.step(action)\n",
    "        score+=reward\n",
    "    print('Episode:{} Score:{}'.format(episode, score))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "bbf92775",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([-0.01018651, -0.00068204, -0.00457492, -0.01299267], dtype=float32),\n",
       " {})"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "env.reset() # for demonstration\n",
    "# env.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "929cffe4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([-0.01020015,  0.19450521, -0.00483478, -0.30711553], dtype=float32),\n",
       " 1.0,\n",
       " False,\n",
       " False,\n",
       " {})"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "env.step(1) # for demonstration, you will get in every step()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cd6ae2cb",
   "metadata": {},
   "source": [
    "## Undestanding enviroment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "c70047b6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Discrete(2)"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "env.action_space # 0 and 1 i.e left and right"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "e6a41fd0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([-3.5071158e+00,  3.1625246e+38,  3.4877753e-01, -6.9282992e+37],\n",
       "      dtype=float32)"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "env.observation_space.sample() #cart pos from -4.b - 4.8, cart velocity, pole angle, pole angular velocity"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dc8929ef",
   "metadata": {},
   "source": [
    "## Training The model\n",
    "#### model-free RL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "3cab9161",
   "metadata": {},
   "outputs": [],
   "source": [
    "# make directories first\n",
    "log_path = os.path.join('Training', 'Logs') # saving tf board logs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "55b70c65",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Training\\\\Logs'"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "log_path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "ad8469c7",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using cpu device\n"
     ]
    }
   ],
   "source": [
    "env = gym.make(enviroment_name) \n",
    "# add ,render_mode='human' in (), removed here because of system resource limitation\n",
    "env = DummyVecEnv([lambda: env]) # wrapped \n",
    "model = PPO('MlpPolicy', env, verbose = 1, tensorboard_log = log_path)\n",
    "# defining agent\n",
    "# policy : multilayer perceptron policy NN\n",
    "# env : enviroment (dummyvectorized)\n",
    "# verbose : = 1 to log result\n",
    "# tensorboard_log : to save logs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1fbf7033",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# PPO??\n",
    "model.learn(total_timesteps = 20000)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2f6a01c7",
   "metadata": {},
   "source": [
    "## Saving the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "56572fed",
   "metadata": {},
   "outputs": [],
   "source": [
    "PPO_Path = os.path.join('Training', 'Saved_Models', 'PPO_Model_CartPole')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "1f11db8e",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save(PPO_Path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "81150e22",
   "metadata": {},
   "outputs": [],
   "source": [
    "# for demonstration not necessary\n",
    "del model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "f2609507",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = PPO.load(PPO_Path, env = env) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "1022f2d4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Training\\\\Saved_Models\\\\PPO_Model_CartPole'"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "PPO_Path"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b821a222",
   "metadata": {},
   "source": [
    "## Testing & Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "78b96ac1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(200.0, 0.0)"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# avg score = 200 is solved \n",
    "evaluate_policy(model, env, n_eval_episodes = 10, render = True)\n",
    "# avg = 200, sd = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "9d0e79d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "#env.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "933a7941",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "54fa4c24",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode:1 Score[200.]\n",
      "Episode:2 Score[200.]\n",
      "Episode:3 Score[200.]\n",
      "Episode:4 Score[200.]\n",
      "Episode:5 Score[200.]\n"
     ]
    }
   ],
   "source": [
    "obs = env.reset()\n",
    "for episode in range(1, episodes+1):\n",
    "    obs = env.reset()\n",
    "    done = False\n",
    "    score = 0\n",
    "    \n",
    "    while not done:\n",
    "        env.render()\n",
    "        action, _ = model.predict(obs) # using model here\n",
    "        obs, reward, done, info= env.step(action)\n",
    "        score += reward\n",
    "    print(\"Episode:{} Score{}\".format(episode, score))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "08429163",
   "metadata": {},
   "outputs": [],
   "source": [
    "#env.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "cf63b39f",
   "metadata": {},
   "outputs": [],
   "source": [
    "#model.predict??"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "2b5702e7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([1], dtype=int64), None)"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.predict(obs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "5338b5b3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "env.action_space.sample()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "522bc8ef",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([[-0.02771483,  0.1484123 ,  0.03494873, -0.3075838 ]],\n",
       "       dtype=float32),\n",
       " array([1.], dtype=float32),\n",
       " array([False]),\n",
       " [{'TimeLimit.truncated': False}])"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "env.step(action) # checking our metrics"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "92362ff5",
   "metadata": {},
   "source": [
    "## Viewing Logs in Tensorboard"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "ee5c242e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Training\\\\Logs\\\\PPO_3'"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "training_log_path = os.path.join(log_path, 'PPO_3')\n",
    "training_log_path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "818d6e58",
   "metadata": {},
   "outputs": [],
   "source": [
    "# !tensorboard --logdir={training_log_path} # use either"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "5b4d606b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# !tensorboard --logdir=\"training_log_path\" --port=8892 \n",
    "# or run in cmd without !\n",
    "# Reinforcement_learning\\Training\\Logs> tensorboard --logdir =.\n",
    "# http://localhost:6006/"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3ce7ba47",
   "metadata": {},
   "source": [
    "## Adding callbacks to training stage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "e6856904",
   "metadata": {},
   "outputs": [],
   "source": [
    "# our training will stop once it hits a benchmark"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "f5fb289c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from stable_baselines3.common.callbacks import EvalCallback, StopTrainingOnRewardThreshold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "f7e59410",
   "metadata": {},
   "outputs": [],
   "source": [
    "save_path = os.path.join('Training', 'Saved_Models')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "44af372b",
   "metadata": {},
   "outputs": [],
   "source": [
    "stop_callback = StopTrainingOnRewardThreshold(reward_threshold=200, verbose=1)\n",
    "eval_callback = EvalCallback(env, \n",
    "                             callback_on_new_best = stop_callback, \n",
    "                             eval_freq = 10000, \n",
    "                             best_model_save_path = save_path, \n",
    "                             verbose = 1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "d9b2ac63",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using cpu device\n"
     ]
    }
   ],
   "source": [
    "model = PPO('MlpPolicy', env, verbose = 1, tensorboard_log = log_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a8f2378e",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "model.learn(total_timesteps = 20000, callback = eval_callback)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5456fce9",
   "metadata": {},
   "source": [
    "## Alternate DQN algorithm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "cc5ff8d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "from stable_baselines3 import DQN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "7cd08eb3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using cpu device\n"
     ]
    }
   ],
   "source": [
    "model = DQN('MlpPolicy', env, verbose = 1, tensorboard_log = log_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9b094d10",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.learn(total_timesteps = 20000, callback = eval_callback)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "731275c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "dqn_path = os.path.join('Training', 'Saved_Models', 'DQN_model')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "59d75b19",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save(dqn_path)\n",
    "#can be loaded and used in a similar way to PPO"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
